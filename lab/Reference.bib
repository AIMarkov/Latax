% Encoding: UTF-8

@InProceedings{leibo1,
  author    = {Joel Z. Leibo and Vin{\'{\i}}cius Flores Zambaldi and Marc Lanctot and Janusz Marecki and Thore Graepel},
  title     = {Multi-agent Reinforcement Learning in Sequential Social Dilemmas},
  booktitle = {Proceedings of the 16th Conference on Autonomous Agents and MultiAgent Systems, {AAMAS} 2017, S{\~{a}}o Paulo, Brazil, May 8-12, 2017},
  year      = {2017},
  pages     = {464--473},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/atal/LeiboZLMG17},
  crossref  = {DBLP:conf/atal/2017},
  timestamp = {Wed, 27 Sep 2017 07:24:00 +0200},
  url       = {http://dl.acm.org/citation.cfm?id=3091194},
}

@InProceedings{lange1,
  author    = {Sascha Lange and Martin A. Riedmiller and Arne Voigtl{\"{a}}nder},
  title     = {Autonomous reinforcement learning on raw visual input data in a real world application},
  booktitle = {The 2012 International Joint Conference on Neural Networks (IJCNN), Brisbane, Australia, June 10-15, 2012},
  year      = {2012},
  pages     = {1--8},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/ijcnn/LangeRV12},
  crossref  = {DBLP:conf/ijcnn/2012},
  doi       = {10.1109/IJCNN.2012.6252823},
  timestamp = {Fri, 26 May 2017 00:50:15 +0200},
  url       = {https://doi.org/10.1109/IJCNN.2012.6252823},
}

@InProceedings{wang1,
  author    = {Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  year      = {2016},
  pages     = {1995--2003},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/icml/WangSHHLF16},
  crossref  = {DBLP:conf/icml/2016},
  timestamp = {Tue, 08 Aug 2017 15:06:57 +0200},
  url       = {http://jmlr.org/proceedings/papers/v48/wangf16.html},
}

@InProceedings{gu1,
  author    = {Shixiang Gu and Timothy P. Lillicrap and Ilya Sutskever and Sergey Levine},
  title     = {Continuous Deep Q-Learning with Model-based Acceleration},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  year      = {2016},
  pages     = {2829--2838},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/icml/GuLSL16},
  crossref  = {DBLP:conf/icml/2016},
  timestamp = {Tue, 12 Jul 2016 21:51:16 +0200},
  url       = {http://jmlr.org/proceedings/papers/v48/gu16.html},
}

@InProceedings{mnih2,
  author    = {Volodymyr Mnih and Adri{\`{a}} Puigdom{\`{e}}nech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning, {ICML} 2016, New York City, NY, USA, June 19-24, 2016},
  year      = {2016},
  pages     = {1928--1937},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/icml/MnihBMGLHSK16},
  crossref  = {DBLP:conf/icml/2016},
  timestamp = {Tue, 12 Jul 2016 21:51:16 +0200},
  url       = {http://jmlr.org/proceedings/papers/v48/mniha16.html},
}

@InProceedings{ganin1,
  author    = {Yaroslav Ganin and Tejas Kulkarni and Igor Babuschkin and S. M. Ali Eslami and Oriol Vinyals},
  title     = {Synthesizing Programs for Images using Reinforced Adversarial Learning},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018},
  year      = {2018},
  pages     = {1652--1661},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/icml/GaninKBEV18},
  crossref  = {DBLP:conf/icml/2018},
  timestamp = {Fri, 13 Jul 2018 14:58:25 +0200},
  url       = {http://proceedings.mlr.press/v80/ganin18a.html},
}

@InProceedings{fent1,
  author    = {Jun Feng and Minlie Huang and Li Zhao and Yang Yang and Xiaoyan Zhu},
  title     = {Reinforcement Learning for Relation Classification From Noisy Data},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018},
  year      = {2018},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/FengHZYZ18},
  crossref  = {DBLP:conf/aaai/2018},
  timestamp = {Thu, 03 May 2018 17:03:19 +0200},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17151},
}

@InProceedings{li1,
  author    = {Jiwei Li and Will Monroe and Alan Ritter and Dan Jurafsky and Michel Galley and Jianfeng Gao},
  title     = {Deep Reinforcement Learning for Dialogue Generation},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2016, Austin, Texas, USA, November 1-4, 2016},
  year      = {2016},
  pages     = {1192--1202},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/emnlp/LiMRJGG16},
  crossref  = {DBLP:conf/emnlp/2016},
  timestamp = {Fri, 04 Nov 2016 14:45:31 +0100},
  url       = {http://aclweb.org/anthology/D/D16/D16-1127.pdf},
}

@InProceedings{silver1,
  author    = {David Silver and Guy Lever and Nicolas Heess and Thomas Degris and Daan Wierstra and Martin A. Riedmiller},
  title     = {Deterministic Policy Gradient Algorithms},
  booktitle = {Proceedings of the 31th International Conference on Machine Learning, {ICML} 2014, Beijing, China, 21-26 June 2014},
  year      = {2014},
  pages     = {387--395},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/icml/SilverLHDWR14},
  crossref  = {DBLP:conf/icml/2014},
  timestamp = {Wed, 29 Mar 2017 16:45:25 +0200},
  url       = {http://jmlr.org/proceedings/papers/v32/silver14.html},
}

@InProceedings{Mujoco1,
  author    = {Emanuel Todorov and Tom Erez and Yuval Tassa},
  title     = {MuJoCo: {A} physics engine for model-based control},
  booktitle = {2012 {IEEE/RSJ} International Conference on Intelligent Robots and Systems, {IROS} 2012, Vilamoura, Algarve, Portugal, October 7-12, 2012},
  year      = {2012},
  pages     = {5026--5033},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/iros/TodorovET12},
  crossref  = {DBLP:conf/iros/2012},
  doi       = {10.1109/IROS.2012.6386109},
  timestamp = {Mon, 22 May 2017 17:11:44 +0200},
  url       = {https://doi.org/10.1109/IROS.2012.6386109},
}

@InProceedings{lowe1,
  author    = {Ryan Lowe and Yi Wu and Aviv Tamar and Jean Harb and Pieter Abbeel and Igor Mordatch},
  title     = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  booktitle = {Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, {USA}},
  year      = {2017},
  pages     = {6382--6393},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/nips/LoweWTHAM17},
  crossref  = {DBLP:conf/nips/2017},
  timestamp = {Mon, 27 Nov 2017 12:38:48 +0100},
  url       = {http://papers.nips.cc/paper/7217},
}

@InProceedings{Hester1,
  author    = {Todd Hester and Matej Vecerik and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Dan Horgan and John Quan and Andrew Sendonaris and Ian Osband and Gabriel Dulac{-}Arnold and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
  title     = {Deep Q-learning From Demonstrations},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018},
  year      = {2018},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/HesterVPLSPHQSO18},
  crossref  = {DBLP:conf/aaai/2018},
  timestamp = {Thu, 03 May 2018 17:03:19 +0200},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16976},
}

@InProceedings{Hasselt1,
  author    = {Hado van Hasselt},
  title     = {Double Q-learning},
  booktitle = {Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010. Proceedings of a meeting held 6-9 December 2010, Vancouver, British Columbia, Canada.},
  year      = {2010},
  pages     = {2613--2621},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/nips/Hasselt10},
  crossref  = {DBLP:conf/nips/2010},
  timestamp = {Thu, 11 Dec 2014 17:34:08 +0100},
  url       = {http://papers.nips.cc/paper/3964-double-q-learning},
}

@InProceedings{Harm1,
  author    = {Harm van Seijen and Hado van Hasselt and Shimon Whiteson and Marco A. Wiering},
  title     = {A theoretical and empirical analysis of Expected Sarsa},
  booktitle = {{IEEE} Symposium on Adaptive Dynamic Programming and Reinforcement Learning, {ADPRL} 2009, Nashville, TN, USA, March 31 - April 1, 2009},
  year      = {2009},
  pages     = {177--184},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/adprl/SeijenHWW09},
  crossref  = {DBLP:conf/adprl/2009},
  doi       = {10.1109/ADPRL.2009.4927542},
  timestamp = {Fri, 26 May 2017 00:49:09 +0200},
  url       = {https://doi.org/10.1109/ADPRL.2009.4927542},
}

@InProceedings{Morimura1,
  author    = {Tetsuro Morimura and Eiji Uchibe and Junichiro Yoshimoto and Kenji Doya},
  title     = {A Generalized Natural Actor-Critic Algorithm},
  booktitle = {Advances in Neural Information Processing Systems 22: 23rd Annual Conference on Neural Information Processing Systems 2009. Proceedings of a meeting held 7-10 December 2009, Vancouver, British Columbia, Canada.},
  year      = {2009},
  pages     = {1312--1320},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/nips/MorimuraUYD09},
  crossref  = {DBLP:conf/nips/2009},
  timestamp = {Thu, 11 Dec 2014 17:34:07 +0100},
  url       = {http://papers.nips.cc/paper/3767-a-generalized-natural-actor-critic-algorithm},
}

@InProceedings{Ciosek1,
  author    = {Kamil Ciosek and Shimon Whiteson},
  title     = {Expected Policy Gradients},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018},
  year      = {2018},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/CiosekW18},
  crossref  = {DBLP:conf/aaai/2018},
  timestamp = {Thu, 03 May 2018 17:03:19 +0200},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16116},
}

@InProceedings{SuttonA1,
  author    = {Richard S. Sutton and David A. McAllester and Satinder P. Singh and Yishay Mansour},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference, Denver, Colorado, USA, November 29 - December 4, 1999]},
  year      = {1999},
  pages     = {1057--1063},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/conf/nips/SuttonMSM99},
  crossref  = {DBLP:conf/nips/1999},
  timestamp = {Thu, 11 Dec 2014 17:34:08 +0100},
  url       = {http://papers.nips.cc/paper/1713},
}

@Article{Gao1,
  author  = {Gao, Y. and Zhou, R. Y. and Wang, H. and Cao, Z. X.},
  title   = {Study on an average reward reinforcement learning algorithm},
  journal = {Chinese Journal of Computers},
  year    = {2007},
  volume  = {30},
  number  = {8},
  pages   = {1372-1378},
}

@Article{silver2,
  author  = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Den Driessche, George Van and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  title   = {Mastering the game of Go with deep neural networks and tree search},
  journal = {Nature},
  year    = {2016},
  volume  = {529},
  number  = {7587},
  pages   = {484--489},
}

@Article{Rummery1,
  author    = {A. Rummery, G and Niranjan, Mahesan},
  title     = {On-Line Q-Learning Using Connectionist Systems},
  year      = {1994},
  month     = {11},
  booktitle = {Technical Report CUED/F-INFENG/TR 166},
}

@Book{sutton1998,
  title     = {Reinforcement learning:an introduction},
  publisher = {The MIT press},
  year      = {1998},
  author    = {Richard S.Sutton and Andrew G.Barto},
}

@Article{Singh1,
  author   = {Singh, Satinder P. and Sutton, Richard S.},
  title    = {Reinforcement learning with replacing eligibility traces},
  journal  = {Machine Learning},
  year     = {1996},
  volume   = {22},
  number   = {1-3},
  pages    = {123--158},
  month    = {Mar},
  issn     = {1573-0565},
  abstract = {The eligibility trace is one of the basic mechanisms used in reinforcement learning to handle delayed reward. In this paper we introduce a new kind of eligibility trace, thereplacing trace, analyze it theoretically, and show that it results in faster, more reliable learning than the conventional trace. Both kinds of trace assign credit to prior events according to how recently they occurred, but only the conventional trace gives greater credit to repeated events. Our analysis is for conventional and replace-trace versions of the offline TD(1) algorithm applied to undiscounted absorbing Markov chains. First, we show that these methods converge under repeated presentations of the training set to the same predictions as two well known Monte Carlo methods. We then analyze the relative efficiency of the two Monte Carlo methods. We show that the method corresponding to conventional TD is biased, whereas the method corresponding to replace-trace TD is unbiased. In addition, we show that the method corresponding to replacing traces is closely related to the maximum likelihood solution for these tasks, and that its mean squared error is always lower in the long run. Computational results confirm these analyses and show that they are applicable more generally. In particular, we show that replacing traces significantly improve performance and reduce parameter sensitivity on the ``Mountain-Car'' task, a full reinforcement-learning problem with a continuous state space, when using a feature-based function approximator.},
  day      = {01},
  doi      = {10.1007/BF00114726},
  url      = {https://doi.org/10.1007/BF00114726},
}

@Article{Watkins1,
  author   = {Watkins, Christopher J. C. H. and Dayan, Peter},
  title    = {Q-learning},
  journal  = {Machine Learning},
  year     = {1992},
  volume   = {8},
  number   = {3},
  pages    = {279--292},
  month    = {May},
  issn     = {1573-0565},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  day      = {01},
  doi      = {10.1007/BF00992698},
  url      = {https://doi.org/10.1007/BF00992698},
}

@Article{williams1,
  author  = {Williams, Ronald J},
  title   = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  journal = {Machine Learning},
  year    = {1992},
  volume  = {8},
  pages   = {229--256},
}

@PhdThesis{Konda1,
  author    = {Vijaymohan Konda},
  title     = {Actor-critic algorithms},
  school    = {Massachusetts Institute of Technology, Cambridge, MA, {USA}},
  year      = {2002},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/phd/ndltd/Konda02},
  timestamp = {Thu, 04 May 2017 16:01:25 +0200},
  url       = {http://hdl.handle.net/1721.1/8120},
}

@Article{peters1,
  author    = {Jan Peters and Stefan Schaal},
  title     = {Natural Actor-Critic},
  journal   = {Neurocomputing},
  year      = {2008},
  volume    = {71},
  number    = {7-9},
  pages     = {1180--1190},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/bib/journals/ijon/PetersS08},
  doi       = {10.1016/j.neucom.2007.11.026},
  timestamp = {Tue, 06 Jun 2017 22:23:28 +0200},
  url       = {https://doi.org/10.1016/j.neucom.2007.11.026},
}

@Book{sutton2017,
  title     = {Reinforcement learning：an introduction(Complete Draft)},
  publisher = {The MIT press},
  year      = {2017},
  author    = {Richard S.Sutton and Andrew G.Barto},
}

@Article{mnih1,
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin A and Fidjeland, Andreas K and Ostrovski, Georg and others},
  title   = {Human-level control through deep reinforcement learning},
  journal = {Nature},
  year    = {2015},
  volume  = {518},
  number  = {7540},
  pages   = {529--533},
}

@Article{lillicraps1,
  author        = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  title         = {Continuous control with deep reinforcement learning},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1509.02971},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/LillicrapHPHETS15},
  eprint        = {1509.02971},
  timestamp     = {Mon, 13 Aug 2018 16:46:11 +0200},
  url           = {http://arxiv.org/abs/1509.02971},
}

@InProceedings{Tangkaratt1,
  author  = {Tangkaratt, Voot and Abdolmaleki, Abbas and Sugiyama, Masashi},
  title   = {Guide Actor-Critic for Continuous Control},
  year    = {2018},
  address = {Vancouver Convention Center, Vancouver CANADA},
  journal = {In Proceedings of the sixth International Conference on Learning Representations},
}

@Article{Wawr1,
  author  = {Wawrzynski, Pawel},
  title   = {Control Policy with Autocorrelated Noise in Reinforcement Learning for Robotics},
  journal = {International Journal of Machine Learning and Computing},
  year    = {2015},
  volume  = {5},
  number  = {2},
  pages   = {91-95},
}

@Article{gym1,
  author        = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  title         = {OpenAI Gym},
  journal       = {CoRR},
  year          = {2016},
  volume        = {abs/1606.01540},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/BrockmanCPSSTZ16},
  eprint        = {1606.01540},
  timestamp     = {Mon, 13 Aug 2018 16:48:42 +0200},
  url           = {http://arxiv.org/abs/1606.01540},
}

@InProceedings{Foerster1,
  author  = {Foerster, Jakob N and Assael, Yannis M and De Freitas, Nando and Whiteson, Shimon},
  title   = {Learning to Communicate with Deep Multi−Agent Reinforcement Learning},
  year    = {2016},
  pages   = {2137--2145},
  address = {Barcelona,SPAIN},
  journal = {In Advances in Neural Information Processing Systems 29},
}

@Article{Heess1,
  author        = {Nicolas Heess and Jonathan J. Hunt and Timothy P. Lillicrap and David Silver},
  title         = {Memory-based control with recurrent neural networks},
  journal       = {CoRR},
  year          = {2015},
  volume        = {abs/1512.04455},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/bib/journals/corr/HeessHLS15},
  eprint        = {1512.04455},
  timestamp     = {Mon, 13 Aug 2018 16:47:14 +0200},
  url           = {http://arxiv.org/abs/1512.04455},
}

@Article{lin2,
  author  = {Lin, Long Ji},
  title   = {Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching},
  journal = {Machine Learning},
  year    = {1992},
  volume  = {8},
  pages   = {293--321},
}

@Article{Uhlenbeck1,
  author  = {Uhlenbeck, George E and Ornstein, Leonard S},
  title   = {On the theory of the brownian motion},
  journal = {Physical review},
  year    = {1930},
}

@Comment{jabref-meta: databaseType:bibtex;}
